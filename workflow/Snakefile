from pathlib import Path
from csv import DictReader, DictWriter
from itertools import groupby
from operator import itemgetter

from snakemake.io import expand, glob_wildcards
from snakemake.utils import validate


## configuration ##

validate(config, "schemas/config.yml")

## variables ##

root = Path("results")
logs = Path("logs")

with open(config["coor"]) as file:
    rows = list(DictReader(file, delimiter="\t"))
    dirs = [Path(row["species"]) / row["gene"] for row in rows]
    species = {row["species"] for row in rows if row["species"]}

## rules ##

rule all:
    input:
        expand(root / "{species}" / "lib.fasta", species = species),
        expand(root / "{dir}" / "qry.{fmt}", dir = dirs, fmt = ("gb", "fasta")),
        expand(root / "{dir}" / "hits.tsv", dir = dirs)

rule meta:
    message: "Split metadata by species."
    input: config["meta"]
    output: expand(root / "{species}" / "meta.tsv", species = species)
    params: root = root, species = species
    run:
        getter = itemgetter("species")
        with open(input[0]) as file1:
            reader = DictReader(file1, delimiter="\t")
            for key, val in groupby(sorted(reader, key = getter), key = getter):
                if key in params.species:
                    path = Path(params.root) / key / "meta.tsv"
                    with path.open("w") as file2:
                        writer = DictWriter(file2, reader.fieldnames, delimiter="\t")
                        writer.writeheader()
                        writer.writerows(list(val))

rule download_libs:
    input: config["meta"]
    output: root / "db.fasta"
    shell:
        """
        awk 'NR > 1 {{ print $1 }}' {input:q} | \
           xargs -L 250 | tr ' ' ',' | \
           xargs -L 1 efetch -db nuccore -format fasta -id > {output:q}
        """

rule extract_libs:
    input:
        root / "{species}" / "meta.tsv",
        rules.download_libs.output
    output:
        root / "{species}" / "lib.fasta"
    shell:
        """
        awk 'NR > 1 {{ print $1 }}' {input[0]:q} | \
            samtools faidx -r - {input[1]:q} > {output:q}
        """

rule download_coor:
    message: "Download query sequences from GenBank with coordinates."
    input: config["coor"]
    output: expand(root / "{dir}" / "qry.{fmt}", dir = dirs, fmt = ("gb", "fasta"))
    params: root
    threads: 1
    shell:
        """
        tail -n +2 {input:q} | \
        while IFS=$'\t' read -r id seq_start seq_stop strand species gene protein_id
        do
          for fmt in gb fasta
          do
            efetch \
              -db nuccore -id "$id" \
              -seq_start "$seq_start" -seq_stop "$seq_stop" -strand "$strand" \
              -format $fmt > {params:q}/"$species/$gene/qry.$fmt"
          done
        done
        """

rule glsearch:
    message: "Run global/local alignment."
    input:
        qry = root / "{species}" / "{gene}" / "qry.fasta",
        lib = root / "{species}" / "lib.fasta"
    output:
        root / "{species}" / "{gene}" / "hits.tsv"
    params: lambda wildcards, output: Path(output[0]).parent.parent
    threads: config["threads"]
    shell:
        """
        glsearch36 -T {threads} -m 8C {input.qry:q} {input.lib:q} > {output:q}
        """
