import fileinput

from pathlib import Path
from csv import DictReader, DictWriter
from itertools import groupby
from collections import defaultdict
from operator import itemgetter

from Bio import SeqIO
from Bio.SeqFeature import FeatureLocation

from snakemake.io import expand, glob_wildcards
from snakemake.utils import validate


## configuration ##

validate(config, "schemas/config.yml")

## variables ##

root = Path("results")
logs = Path("logs")

with open(config["gene"]) as file:
  rows = list(DictReader(file, delimiter="\t"))
  dirs = [Path(row["species"]) / row["gene"] for row in rows]
  outs = [row["species"] + "-" + row["gene"] for row in rows]
  species = {row["species"] for row in rows}

with open(config["meta"]) as file:
  ntype = defaultdict(set)
  for row in DictReader(file, delimiter="\t"):
      ntype[row["species"]].add(row["type"])

## functions ##

def trait_columns(wildcards, output):
    return "location" + " type" * (len(ntype[Path(output[0]).parent.parent.name]) > 1)

## rules ##

rule all:
  input:
    expand(root / config["out"] / "{out}.json", out = outs)

rule download_db:
  input: config["meta"]
  output: root / "db.fasta"
  shell:
    """
    awk 'NR > 1 {{ print $1 }}' {input:q} | \
      xargs -L 250 | tr ' ' ',' | \
      xargs -L 1 efetch -db nuccore -format fasta -id > {output:q}
    """

rule download_gene:
  message: "Download sequences from GenBank with coordinates."
  input: config["gene"]
  output: expand(root / "{dir}" / "ref.gb", dir = dirs)
  params: root
  shell:
    """
    tail -n +2 {input:q} | \
    while IFS=$'\t' read -r id seq_start seq_stop strand species gene
    do
      efetch \
        -db nuccore -id "$id" \
        -seq_start "$seq_start" -seq_stop "$seq_stop" -strand "$strand" \
        -format gb > {params:q}/"$species/$gene/ref.gb"
    done
    """

rule metadata:
  message: "Split metadata by species."
  input: config["meta"]
  output: expand(root / "{species}" / "meta.tsv", species = species)
  params: root = root, species = species
  run:
    getter = itemgetter("species")
    with open(input[0]) as file1:
      reader = DictReader(file1, delimiter="\t")
      for key, val in groupby(sorted(reader, key = getter), key = getter):
        if key in params.species:
          path = Path(params.root) / key / "meta.tsv"
          with path.open("w") as file2:
            writer = DictWriter(file2, reader.fieldnames, delimiter="\t")
            writer.writeheader()
            writer.writerows(list(val))

rule coordinates:
  input: root / "{species}" / "meta.tsv"
  output: root / "{species}" / "coor.tsv"
  script: "scripts/neogeocoor.R"

rule exactify_gene:
    input: root / "{species}" / "{gene}" / "ref.gb"
    output: root / "{species}" / "{gene}" / "qry.gb"
    run:
      def exactify(features):
        for ele in features:
          loc = ele.location
          if loc is not None:
            ele.location = FeatureLocation(int(loc.start), int(loc.end), loc.strand)
            yield ele
      # -
      rec = SeqIO.read(input[0], "gb")
      rec.features = list(exactify(rec.features))
      SeqIO.write(rec, output[0], "gb")

rule fastafy_gene:
  input: rules.exactify_gene.output
  output: root / "{species}" / "{gene}" / "qry.fasta"
  run: SeqIO.convert(input[0], "gb", output[0], "fasta")

rule extract_libs:
  input:
    root / "{species}" / "meta.tsv",
    rules.download_db.output
  output:
    root / "{species}" / "lib.fasta"
  shell:
    """
    awk 'NR > 1 {{ print $1 }}' {input[0]:q} | \
        samtools faidx -r - {input[1]:q} > {output:q}
    """

rule glsearch:
  message: "Run global/local alignment."
  input:
    qry = rules.fastafy_gene.output,
    lib = root / "{species}" / "lib.fasta"
  output:
    root / "{species}" / "{gene}" / "hits.tsv"
  params:
    lambda wildcards, output: Path(output[0]).parent.name
  threads: config["threads"]
  shell:
    """
    if [ {params:q} = "genome" ]; then
      glsearch36 -3 -m 8C {input.qry:q} {input.qry:q} > {output:q}
    else
      glsearch36 -T {threads} -m 8C {input.qry:q} {input.lib:q} > {output:q}
    fi
    """

rule extract_hits:
  input:
    hits = rules.glsearch.output,
    meta = root / "{species}" / "meta.tsv"
  output:
    tsv = root / "{species}" / "{gene}" / "reg.tsv"
  script: "scripts/extract_hits.R"

rule extract_seqs:
  input:
    tsv = rules.extract_hits.output,
    lib = root / "{species}" / "lib.fasta"
  output:
    root / "{species}" / "{gene}" / "seq.fasta"
  params:
    lambda wildcards, output: Path(output[0]).parent.name
  shell:
    """
    if [ {params:q} = "genome" ]; then
      sed -e '/^[^>]/ s/[^ACGTNacgtn-]/n/g' {input.lib:q} > {output:q}
    else
      {{
        grep plus  {input.tsv:q} | cut -f 2 | samtools faidx --mark-strand no -r -    {input.lib:q} || true
        grep minus {input.tsv:q} | cut -f 2 | samtools faidx --mark-strand no -r - -i {input.lib:q} || true
      }} | \
        sed -E -e '/^>/ s/:.*//g' -e '/^[^>]/ s/[^ACGTNacgtn-]/n/g' > {output:q}
    fi
    """

rule mafft:
  input: rules.extract_seqs.output
  output: root / "{species}" / "{gene}" / "msa.fasta"
  log: root / "{species}" / "{gene}" / "msa.log"
  threads: config["threads"]
  shell: "mafft --auto --thread {threads} {input:q} > {output:q} 2> {log:q}"

rule gubbins:
  message: "Infer maximum-likelihood tree and recombination events."
  input: rules.mafft.output
  output: root / "{species}" / "{gene}" / "gub.final_tree.tre"
  params:
    pwd = Path().absolute(),
    root = lambda wildcards, output: Path(output[0]).parent,
    itr = config["itr"],
    gap = config["gap"]
  threads: config["threads"]
  shell:
    """
    mkdir -p {params.root:q} && cd {params.root:q} || exit
    run_gubbins.py \
      {params.pwd:q}/{input:q} \
      -i {params.itr} -f {params.gap} -p gub -c {threads} > gub.log
    """

rule bactdate:
  message: "Infer recombination-aware chronogram using BactDating."
  input:
    tree = rules.gubbins.output,
    meta = root / "{species}" / "meta.tsv"
  output:
    res = root / "{species}" / "{gene}" / "bactdate-{model}.qs"
  params:
    mod = lambda wildcards, output: Path(output[0]).stem.split("-", maxsplit = 1)[-1],
    nbi = config["nbIts"],
    thn = config["thin"],
    seed = config["seed"]
  script: "scripts/bactdate.R"

rule bestmodel:
  input: expand(root / "{{species}}" / "{{gene}}" / "bactdate-{model}.qs", model = config["model"])
  output:
    tree = root / "{species}" / "{gene}" / "bactdate.tree",
    json = root / "{species}" / "{gene}" / "bactdate.json"
  params: config["threads"]
  threads: config["threads"]
  script: "scripts/bestmodel.R"

rule ancestral:
  message: "Reconstructing ancestral sequences and mutations"
  input:
    tree = rules.bestmodel.output.tree,
    msa = rules.mafft.output
  output:
    seqs = root / "{species}" / "{gene}" / "ancestral.fasta",
    json = root / "{species}" / "{gene}" / "nt_muts.json"
  params: config["threads"]
  threads: config["threads"]
  script: "scripts/ancestral.R"

rule translate:
  message: "Translating amino acid sequences"
  input:
    tree = rules.bestmodel.output.tree,
    node_data = rules.ancestral.output.json,
    reference = root / "{species}" / "{gene}" / "qry.gb"
  output:
    root / "{species}" / "{gene}" / "aa_muts.json"
  shell:
    """
    augur translate \
      --tree {input.tree:q} \
      --ancestral-sequences {input.node_data:q} \
      --reference-sequence {input.reference:q} \
      --output-node-data {output:q} \
    """

rule traits:
  message: "Inferring ancestral traits for {params.columns!s}"
  input:
    tree = rules.bestmodel.output.tree,
    metadata = root / "{species}" / "meta.tsv"
  output:
    root / "{species}" / "{gene}" / "traits.json"
  params:
    columns = trait_columns
  shell:
    """
    augur traits \
      --tree {input.tree:q} \
      --metadata {input.metadata:q} \
      --output-node-data {output:q} \
      --columns {params.columns} \
      --confidence
    """

rule export:
  message: "Exporting data files for for auspice"
  input:
    tree = rules.bestmodel.output.tree,
    metadata = root / "{species}" / "meta.tsv",
    branch_lengths = rules.bestmodel.output.json,
    traits = rules.traits.output,
    nt_muts = rules.ancestral.output.json,
    aa_muts = rules.translate.output,
    lat_longs = rules.coordinates.output
  output:
    auspice_json = root / config["out"] / "{species}-{gene}.json"
  params:
    auspice_config = config["conf"]
  shell:
    """
    augur export v2 \
      --tree {input.tree:q} \
      --metadata {input.metadata:q} \
      --node-data {input.branch_lengths:q} {input.nt_muts:q} {input.aa_muts:q} {input.traits:q} \
      --lat-longs {input.lat_longs:q} \
      --auspice-config {params.auspice_config:q} \
      --output {output.auspice_json:q}
    """
