from pathlib import Path

from snakemake.io import expand
from snakemake.utils import validate


## configuration ##

validate(config, "schemas/config.yml")

## variables ##

root = Path(config["out"])

## rules ##

####################################################################################################
# Generate measureably-evolving population data set
####################################################################################################

rule mkff:
  output: 
    root / config["repo"] / "genbank" / "ff.db"
  params:
    rettype = "gb",
    repo = root / config["repo"] / "genbank" / "ff",
    term = config["term"],
    email = config["email"]
  shell:
    """
    python -m ffbio.ffdb {params.repo:q} -term {params.term:q} -rettype {params.rettype} -email {params.email}
    """

rule meta:
  input: rules.mkff.output
  output: root / config["repo"] / "meta" / "meta.tsv"
  threads: config["threads"]
  shell:
    """
    python -m ffbio.ffidx {input:q} -dump -fo gb | \
    python -m ffbio.ffqual - db_xref collection_date country | \
    awk -F '\t' -v OFS='\t' 'NR == 1 {{ print "strain", $0; }} NR > 1 {{ print $1, $0; }}' | \
    Rscript --vanilla ./workflow/scripts/date.R - $'\t' date %Y-%m-%d collection_date dbY Ymd bY Y | \
    awk -F '\t' '$7 != "?"' | \
    Rscript --vanilla ./workflow/scripts/geog.R - $'\t' country "[:,]" {threads} > \
    {output:q}
    """

rule coor:
  input: rules.meta.output
  output: root / config["repo"] / "meta" / "coor.tsv"
  shell:
    """
    awk -F '\t' -v OFS='\t' 'NR > 1 {{ print "location", $7, $8, $9; }}' {input:q} | sort -u > {output:q}
    """

rule taxa:
  input:
    repo = rules.mkff.output,
    date = rules.meta.output
  output:
    root / config["repo"] / "meta" / "taxid.ssv"
  shell:
    """
    awk -F '\t' 'NR > 1 {{ print $1; }}' {input.date:q} | \
    python -m ffbio.ffidx {input.repo:q} -batch - -fo gb | \
    python -m ffbio.ffqual - db_xref | \
    awk -F '\t' 'NR > 1 {{ match($2, /taxon:([0-9]+)/, arr); print $1, arr[1] ? arr[1] : 0; }}' > \
    {output:q}
    """

rule mkdb:
  input:
    repo = rules.mkff.output,
    taxa = rules.taxa.output
  params:
    root / config["repo"] / "blast" / "db"
  output:
    expand(
      root / config["repo"] / "blast" / "db.{ext}",
      ext = ("log", "ndb", "nhd", "nin", "nog", "nos", "not", "nsq", "ntf", "nto", "perf")
    )
  shell:
    """
    cut -f 1 -d ' ' {input.taxa:q} | \
    python -m ffbio.ffidx {input.repo:q} -batch - | \
    makeblastdb \
      -in - -input_type fasta -dbtype nucl -title db -parse_seqids -hash_index \
      -out {params:q} -blastdb_version 5 -logfile {params:q}.log -taxid_map {input.taxa:q}
    """

rule reference:
  input: rules.mkff.output
  params: config["accv"]
  output:
    fasta = root / config["name"] / "ref.fasta",
    genbank = root / config["name"] / "ref.gb"
  shell:
    """
    python -m ffbio.ffidx {input:q} -entry {params:q} -fo fasta > {output.fasta:q}
    python -m ffbio.ffidx {input:q} -entry {params:q} -fo genbank | \
      ./workflow/scripts/add_locus_tag.py > \
      {output.genbank:q}
    """

rule blast:
  input:
    rules.reference.output.fasta
  params:
    db = root / config["repo"] / "blast" / "db",
    accv = config["accv"],
    num_alignments = 20000
  output:
    root / config["name"] / "blast.tsv"
  threads:
    config["threads"]
  shell:
    """
    blastn \
      -task megablast \
      -db {params.db:q} \
      -query {input:q} \
      -outfmt "7 std qlen sstrand staxid stitle" \
      -num_threads {threads} \
      -num_alignments {params.num_alignments:q} \
      -subject_besthit > \
      {output:q}
    """

rule qpidcov:
  input: rules.blast.output
  output: root / config["name"] / "pidcov.tsv"
  shell:
    """
    {{
      printf "accver\tqpidcov\n";
      awk -F '\t' -v OFS='\t' '/^[^#]/ {{ print $2, ($8 - $7 + 1) / $13 * $3 / 100; }}' {input:q} | \
      sort -n -r -k 2;
    }} > \
    {output:q}
    """
    
rule blastdbcmd:
  input:
    rules.qpidcov.output
  params:
    db = root / config["repo"] / "blast" / "db",
    qpidcov = 0.975
  output:
    root / config["name"] / "seqs.fasta"
  shell:
    """
    awk -F '\t' -v OFS='\t' -v qpidcov={params.qpidcov:q} 'NR > 1 && $2 >= qpidcov {{ print $1; }}' {input:q} | \
    blastdbcmd -db {params.db} -entry_batch - | \
    sed -e "s/ .*//g" -e "/^[^>]/ s/[^ACGTNacgtn-]/n/g" > \
    {output:q}
    """

####################################################################################################
# phylogeny
####################################################################################################

rule mafft:
  input: rules.blastdbcmd.output
  output: root / config["name"] / "msa.fasta"
  log: root / config["name"] / "msa.log"
  threads: config["threads"]
  shell: 
    """
    mafft --auto --thread {threads} {input:q} > {output:q} 2> {log:q}
    """

rule iqtree:
  input: 
    rules.mafft.output
  params: 
    prefix = root / config["name"] / "iqt",
    seed = config["seed"],
    alrt = 1000,
    bb = 1000
  output:
    expand(
      root / config["name"] / "iqt.{ext}",
      ext = ("bionj", "ckp.gz", "contree", "iqtree", "mldist", "model.gz", "splits.nex", "state", "ufboot")
    ),
    tree = root / config["name"] / "iqt.treefile"
  log:
    root / config["name"] / "iqt.log"
  threads:
    config["threads"]
  shell:
    """
    iqtree \
      --prefix {params.prefix:q} --seed {params.seed:q} --redo --quiet \
      --threads-max {threads} --allnni -bnni -alrt {params.alrt:q} -bb {params.bb:q} --ancestral \
      -s {input:q} 2> /dev/null
    """

rule gubbins:
  input: 
    msa = rules.mafft.output,
    tree = rules.iqtree.output.tree
  output:
    expand(
      root / config["name"] / "gub.{ext}",
      ext = (
        "branch_base_reconstruction.embl", 
        "filtered_polymorphic_sites.fasta", "filtered_polymorphic_sites.phylip", 
        "node_labelled.final_tree.tre", 
        "per_branch_statistics.csv",  
        "recombination_predictions.embl", "recombination_predictions.gff", 
        "summary_of_snp_distribution.vcf"
      )
    ),
    tree = root / config["name"] / "gub.final_tree.tre"
  params:
    pwd = Path().absolute(),
    root = root / config["name"],
    itr = config["itr"],
    gap = config["gap"]
  log:
    root / config["name"] / "gub.log"
  threads: 
    config["threads"]
  shell:
    """
    cd {params.root:q} || exit && \
    run_gubbins.py {params.pwd:q}/{input.msa:q} -s {params.pwd:q}/{input.tree:q} -i {params.itr} -f {params.gap} -p gub -c {threads} > gub.log
    """

rule bactdate:
  message: "Infer recombination-aware chronogram using BactDating."
  input:
    tree = rules.gubbins.output.tree,
    meta = rules.meta.output
  output:
    expand(
      root / config["name"] / "bac-{model}.{ext}", 
      model = config["model"], 
      ext = ("qs", "tree")
    ),
    tsv = root / config["name"] / "bac.tsv",
    tree = root / config["name"] / "bac.tree",
    json = root / config["name"] / "bac.json"
  threads:
    config["threads"]
  params:
    root = str(root.joinpath(config["name"])),
    model = config["model"],
    nbIts = config["nbIts"],
    thin = config["thin"],
    burn = config["burn"],
    seed = config["seed"]
  script: "scripts/bactdate.R"

rule ancestral:
  message: "Reconstructing ancestral sequences and mutations"
  input:
    tree = rules.bactdate.output.tree,
    msa = rules.mafft.output
  output:
    seqs = root / config["name"] / "ancestral.fasta",
    json = root / config["name"] / "muts-nt.json"
  threads: config["threads"]
  script: "scripts/ancestral.R"

rule translate:
  message: "Translating amino acid sequences"
  input:
    tree = rules.bactdate.output.tree,
    json = rules.ancestral.output.json,
    reference = rules.reference.output.genbank
  output:
    root / config["name"] / "muts-aa.json"
  shell:
    """
    augur translate \
      --tree {input.tree:q} \
      --ancestral-sequences {input.json:q} \
      --reference-sequence {input.reference:q} \
      --output-node-data {output:q}
    """

rule traits:
  message: "Inferring ancestral traits for {params.columns!s}"
  input:
    tree = rules.bactdate.output.tree,
    meta = rules.meta.output
  output:
    root / config["name"] / "traits.json"
  params:
    columns = "location"
  shell:
    """
    augur traits \
      --tree {input.tree:q} \
      --metadata {input.meta:q} \
      --output-node-data {output:q} \
      --columns {params.columns} \
      --confidence
    """

rule export:
  message: "Exporting data files for for auspice"
  input:
    tree = rules.bactdate.output.tree,
    branch_lengths = rules.bactdate.output.json,
    muts_nt = rules.ancestral.output.json,
    muts_aa = rules.translate.output,
    traits = rules.traits.output,
    meta = rules.meta.output,
    coor = rules.coor.output
  params:
    auspice = config["auspice"],
  output:
    root / config["name"] / "auspice.json"
  shell:
    """
    augur export v2 \
      --tree {input.tree:q} \
      --node-data {input.branch_lengths:q} {input.muts_nt:q} {input.muts_aa:q} {input.traits:q} \
      --output {output:q} \
      --auspice-config {params.auspice:q} \
      --metadata {input.meta:q} \
      --lat-longs {input.coor:q}
    """
